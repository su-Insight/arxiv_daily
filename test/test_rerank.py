import json
from src.rerank import rerank_paper  # ç¡®ä¿è·¯å¾„æ­£ç¡®

# 1. æ¨¡æ‹Ÿè®ºæ–‡å¯¹è±¡ç±»
class MockPaper:
    def __init__(self, arxiv_id, title, summary):
        self.arxiv_id = arxiv_id
        self.title = title
        self.summary = summary
        self.score = 0

# 2. å‡†å¤‡æµ‹è¯•ç”¨ä¾‹
def run_semantic_test():
    # å…´è¶£ç›®æ ‡ï¼šLLM ç®—æ³•ä¸æ¨ç†ä¼˜åŒ–
    target = "Large Language Models Reasoning and Inference Optimization"
    # target = "Applications of Large Language Models"

    test_papers = [
        # --- 1. æ ¸å¿ƒç›®æ ‡ (åº”å¾—é«˜åˆ†: 90-100) ---
        MockPaper(
            "2401.STEP",
            "STEP: Step-level Trace Evaluation and Pruning",
            "We propose a novel pruning framework that evaluates reasoning steps using hidden states and dynamically prunes unpromising traces during generation to reduce end-to-end latency in LLMs."
        ),

        # --- 2. åº”ç”¨å±‚é™·é˜± (åº”å¾—ä½åˆ†: < 20) ---
        # è™½ç„¶åŒ…å« LLMï¼Œä½†æ ¸å¿ƒæ˜¯è¡Œæ”¿/ç¿»è¯‘å·¥å…·ä½¿ç”¨ï¼Œæ— ç®—æ³•åˆ›æ–°
        MockPaper(
            "TRAP.APP",
            "Improving Internal Corporate Newsletters with LLM-based Translation",
            "We demonstrate a workflow for using ChatGPT to translate internal corporate memos into five different languages to improve employee engagement in multinational firms."
        ),

        # --- 3. æœ¯è¯­æ··æ·†é™·é˜± (åº”å¾—ä½åˆ†: < 10) ---
        # åˆ©ç”¨â€œAttentionâ€åœ¨ç”Ÿç‰©é¢†åŸŸçš„å«ä¹‰ï¼Œæµ‹è¯•æ¨¡å‹æ˜¯å¦åªçœ‹å…³é”®è¯
        MockPaper(
            "TRAP.BIO",
            "Attention Mechanisms in Protein Folding Sequences",
            "In this biological study, we analyze the attention patterns of amino acid chains during protein synthesis. We identify how specific sequences attract molecular binders."
        ),

        # --- 4. è½¯ç§‘å­¦/ä¼¦ç†é™·é˜± (åº”å¾—ä½åˆ†: < 15) ---
        # è®¨è®ºç¤¾ä¼šå½±å“è€Œéç¡¬æ ¸æŠ€æœ¯
        MockPaper(
            "TRAP.SOC",
            "The Sociological Impact of Generative AI on Remote Work Culture",
            "Through a series of interviews, we explore how the rise of LLMs has changed the way remote workers perceive their job security and daily social interactions."
        ),

        # --- 5. çº¯ç¡¬ä»¶/è®¾æ–½é™·é˜± (åº”å¾—ä½åˆ†: 0-10) ---
        # è™½ç„¶æåˆ° LLM GPUï¼Œä½†å±äºåœŸæœ¨/æš–é€šå·¥ç¨‹
        MockPaper(
            "2401.COOL",
            "Liquid Cooling Systems for GPU Clusters",
            "Optimizing liquid cooling systems for data centers hosting massive H100 GPU clusters used for Large Language Models (LLM) inference to prevent thermal throttling."
        ),

        # --- 6. æ³•å¾‹/åˆè§„é™·é˜± (åº”å¾—ä½åˆ†: 10-20) ---
        # æ³•å¾‹åˆ†æè€Œéç®—æ³•æ”¹è¿›
        MockPaper(
            "2401.LEGAL",
            "Copyright Infringement in AI Training",
            "A legal analysis of copyright infringement liability regarding training data used in Large Language Models (LLM) and the implications for digital intellectual property law."
        ),

        # --- 7. ç¡¬æ ¸ä½†æ— å…³é™·é˜± (åº”å¾—ä½åˆ†: 0) ---
        # æŠ€æœ¯æ·±åº¦å¾ˆé«˜ï¼Œä½†é¢†åŸŸå®Œå…¨é”™ä½ï¼ˆæ•°æ®åº“ç´¢å¼•ï¼‰
        MockPaper(
            "TRAP.DB",
            "B-Tree Indexing Optimization for Real-time SQL Queries",
            "We propose a novel dynamic B-Tree rebalancing algorithm that reduces disk I/O latency by 30% for high-concurrency SQL databases in large-scale distributed systems."
        ),

        # --- 8. æœºå™¨äºº/ç‰©ç†åŠ¨ä½œé™·é˜± (åº”å¾—ä½åˆ†: < 20) ---
        # æµ‹è¯•å¯¹â€œAction-basedâ€ä¸€è¯çš„ç†è§£ï¼ˆç‰©ç†åŠ¨ä½œ vs é€»è¾‘æ¨ç†ï¼‰
        MockPaper(
            "TRAP.ROBOT",
            "Trajectory Planning for Quadrupedal Robots in Rugged Terrain",
            "This paper presents a reinforcement learning approach for real-time action planning in four-legged robots to maintain stability while traversing uneven rocky surfaces."
        )
    ]

    print(f"ğŸ” Testing Semantic Discrimination for: '{target}'\n")

    # 3. è°ƒç”¨ä½ çš„é‡æ’åºå‡½æ•°
    # æ³¨æ„ï¼šè¿™é‡Œä¼šåŠ è½½æœ¬åœ° Llama æ¨¡å‹ï¼Œç¬¬ä¸€æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢
    results = rerank_paper(test_papers, target)

    # 4. ç»“æœåˆ†æ
    print("\n--- Test Results ---")
    for i, p in enumerate(results):
        status = "âœ… PASS" if (p.arxiv_id == "2401.STEP" and i == 0) else "âŒ FAIL"
        # ç†æƒ³æƒ…å†µæ˜¯ STEP æ‹¿ç¬¬ä¸€ï¼Œä¸”åˆ†æ•°è¿œé«˜äºå…¶ä»–ä¸¤ç¯‡
        print(f"Rank {i+1}: [{p.score}] {p.title}")
        if p.arxiv_id == "2401.STEP":
            target_score = p.score
        else:
            distractor_score = p.score

    print("\n--- Analysis ---")
    if target_score > distractor_score + 30:
        print("ğŸ¯ Great! The model distinguishes between 'Core Tech' and 'Peripheral Keywords'.")
    else:
        print("âš ï¸ Warning: The score gap is too small. You might need to refine the Prompt.")

if __name__ == "__main__":
    run_semantic_test()